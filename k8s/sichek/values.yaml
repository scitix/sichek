# Default values for sichek.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

name: sichek
namespace: hi-sys-monitor

image:
  repository: registry-ap-southeast.scitix.ai/hisys/sichek
  pullPolicy: Always #IfNotPresent
  tag: "latest"

mode: daemon # Options: "diagnostic" (one-time health check) or "daemon" (continuous health check)
nodeName: "" # Define the node name to diagnostic; leave it empty if not specified
defaultSpec: default # Define the default spec for sichek
os: "ubuntu" # Define the os for sichek run, options: ubuntu, centos
schedulerName: "si-scheduler" # Define the scheduler name
roceSharedMode: none # specified RDMA shared mode, options: vf, macvlan, none
sichekSpecUrl: https://oss-ap-southeast.scitix.ai/hisys-sichek/specs

daemon:
  gpuLabel: "" # Define the gpu node label to deploy sichek daemon; leave it empty if not specified
  cpuLabel: "" # Define the cpu node label to deploy sichek daemon; leave it empty if not specified
  updateStrategy: OnDelete # updateStrategy RollingUpdate/ OnDelete

batchjob:
  name: "diag"
  gpu: true # Define the gpu node name to diagnostic; set it false if cpu node to diagnostic
  parallelism: 1 # Define the number of parallel pods for the batch Job
  completions: 1 # Define the number of completions for the batch Job
  cmd: "sichek all -e -I podlog,gpuevents,nccltest"
  nodeAffinityHosts: []

mpijob:
  name: "nccl-test"
  numWorkers: 2
  slotsPerWorker: 8
  nodeAffinityHosts: []

pytorchjob:
  name: "model-test"
  numWorkers: 2
  nodeAffinityHosts: []

serviceAccount:
  create: true
  automount: true
  annotations: {}
  name: "sa-sichek"

clusterRole:
  name: "cluster-role-sichek"

clusterRoleBinding:
  name: "cluster-role-binding-sichek"

podAnnotations: {}
podLabels: {}

podSecurityContext: {} # fsGroup: 2000

securityContext:
  privileged: true

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  limits:
    cpu: 10
    memory: 10Gi
  requests:
    cpu: 100m
    memory: 2Mi

# Additional volumes on the output Deployment definition.
volumes:
- name: host-dev
  hostPath:
    path: /dev
- name: host-sys
  hostPath:
    path: /sys
- name: host-log
  hostPath:
    path: /var/log
- name: host-adm
  hostPath:
    path: /var/adm
- name: host-var-lib-kubelet
  hostPath:
    path: /var/lib/kubelet

extraVolumesForDeploy:
- name: host-run-nvidia-fabricmanager
  hostPath:
    path: /run/nvidia-fabricmanager
- name: host-run-nvidia-persistenced
  hostPath:
    path: /run/nvidia-persistenced
- name: nvidia-bin
  hostPath:
    path: /usr/bin/nvidia-smi
- name: nvidia-persistenced
  hostPath:
    path: /usr/bin/nvidia-persistenced
- name: centos-nvidia-lib
  hostPath:
    path: /usr/lib64
    type: DirectoryOrCreate
- name: ubuntu-nvidia-lib
  hostPath:
    path: /usr/lib/x86_64-linux-gnu
    type: DirectoryOrCreate
# Additional volumeMounts on the output Deployment definition.
volumeMounts:
- name: host-dev
  mountPath: /dev
  readOnly: true
- name: host-sys
  mountPath: /sys
  readOnly: true
- name: host-log
  mountPath: /var/log
  readOnly: true
- name: host-adm
  mountPath: /var/adm
  readOnly: true
- name: host-var-lib-kubelet
  mountPath: /var/lib/kubelet
  readOnly: true

extraVolumeMountsForDeploy:
- name: host-run-nvidia-fabricmanager
  mountPath: /run/nvidia-fabricmanager
  readOnly: true
- name: host-run-nvidia-persistenced
  mountPath: /run/nvidia-persistenced
  readOnly: true
- name: nvidia-persistenced
  mountPath: /usr/bin/nvidia-persistenced
  readOnly: true
- name: nvidia-bin
  mountPath: /usr/bin/nvidia-smi
  name: nvidia-bin
  readOnly: true
- name: ubuntu-nvidia-lib
  mountPath: /host-usr/lib/x86_64-linux-gnu/
  readOnly: true
- name: centos-nvidia-lib
  mountPath: /host-usr/lib64/
  readOnly: true
nodeSelector: {}

tolerations: []

affinity: {}
